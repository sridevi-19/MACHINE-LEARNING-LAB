{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/dataset-1.csv\n/kaggle/input/ceacea/cea.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndata=pd.DataFrame(data=pd.read_csv('/kaggle/input/dataset/dataset-1.csv'))\nconcepts= np.array(data.iloc[:,0:-1])\nprint(concepts)\ntarget=np.array(data.iloc[:,-1])\nprint(target)\ndef learn(concepts,target):\n    print(concepts)\n    specific_h=concepts[0].copy()\n    print('initialization of specific_h and general_h')\n    print(specific_h)\n    general_h=[['?' for i in range(len(specific_h))]\n              for i in range(len(specific_h))]\n    print(general_h)\n    for i,h in enumerate(concepts):\n        if target[i]=='yes':\n            for x in range(len(specific_h)):\n                if h[x] != specific_h[x]:\n                    specific_h[x]='?'\n                    general_h[x][x]='?'\n                print(specific_h)\n        print(specific_h)\n        if target[i]=='no':\n            for x in range(len(specific_h)):\n                if h[x]!=specific_h[x]:\n                    general_h[x][x]= specific_h[x]\n                else:\n                    general_h[x][x]='?'\n        print('steps of candidate elimination', i+1)\n        print(specific_h)\n    indices=[i for i,val in enumerate(general_h) if val == ['?','?','?','?','?','?']]\n    for i in indices:\n        general_h.remove(['?','?','?','?','?','?'])\n    return specific_h,general_h\ns_final,g_final = learn(concepts,target)\nprint('final specific_h : ', s_final, sep='\\n')\nprint('final general_h : ', g_final,sep='\\n')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:45:30.808687Z","iopub.execute_input":"2023-04-12T09:45:30.809603Z","iopub.status.idle":"2023-04-12T09:45:30.837918Z","shell.execute_reply.started":"2023-04-12T09:45:30.809555Z","shell.execute_reply":"2023-04-12T09:45:30.836857Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n ['sunny' 'warm' 'high' 'strong' 'warm' 'same']\n [' rainy' 'cold' 'high' 'strong' 'warm' 'change']\n ['sunny' 'warm' 'high' 'strong' 'cool' 'change']]\n['yes' 'yes' 'no' 'yes']\n[['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n ['sunny' 'warm' 'high' 'strong' 'warm' 'same']\n [' rainy' 'cold' 'high' 'strong' 'warm' 'change']\n ['sunny' 'warm' 'high' 'strong' 'cool' 'change']]\ninitialization of specific_h and general_h\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\nsteps of candidate elimination 1\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\nsteps of candidate elimination 2\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\nsteps of candidate elimination 3\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' 'warm' 'same']\n['sunny' 'warm' '?' 'strong' '?' 'same']\n['sunny' 'warm' '?' 'strong' '?' '?']\n['sunny' 'warm' '?' 'strong' '?' '?']\nsteps of candidate elimination 4\n['sunny' 'warm' '?' 'strong' '?' '?']\nfinal specific_h : \n['sunny' 'warm' '?' 'strong' '?' '?']\nfinal general_h : \n[['sunny', '?', '?', '?', '?', '?'], ['?', 'warm', '?', '?', '?', '?']]\n","output_type":"stream"}]}]}
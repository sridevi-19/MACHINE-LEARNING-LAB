{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-03T09:26:25.353842Z","iopub.execute_input":"2023-05-03T09:26:25.354279Z","iopub.status.idle":"2023-05-03T09:26:25.366700Z","shell.execute_reply.started":"2023-05-03T09:26:25.354246Z","shell.execute_reply":"2023-05-03T09:26:25.365632Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/decision/DECISION.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport math\nimport numpy as np\n\ndata = pd.read_csv(\"/kaggle/input/roshan/3-dataset.csv\")\nfeatures = [feat for feat in data]\nfeatures.remove(\"answer\")\n\n\nclass Node:\n    def __init__(self):\n        self.children = []\n        self.value = \"\"\n        self.isLeaf = False\n        self.pred = \"\"\n\n\ndef entropy(examples):\n    pos = 0.0\n    neg = 0.0\n    for _, row in examples.iterrows():\n        if row[\"answer\"] == \"yes\":\n            pos += 1\n        else:\n            neg += 1\n    if pos == 0.0 or neg == 0.0:\n        return 0.0\n    else:\n        p = pos / (pos + neg)\n        n = neg / (pos + neg)\n        return -(p * math.log(p, 2) + n * math.log(n, 2))\n\n\ndef info_gain(examples, attr):\n    uniq = np.unique(examples[attr])\n    #print (\"\\n\",uniq)\n    gain = entropy(examples)\n    #print (\"\\n\",gain)\n    for u in uniq:\n        subdata = examples[examples[attr] == u]\n        #print (\"\\n\",subdata)\n        sub_e = entropy(subdata)\n        gain -= (float(len(subdata)) / float(len(examples))) * sub_e\n        #print (\"\\n\",gain)\n    return gain\n\ndef ID3(examples, attrs):\n    root = Node()\n\n    max_gain = 0\n    max_feat = \"\"\n    for feature in attrs:\n        #print (\"\\n\",examples)\n        gain = info_gain(examples, feature)\n        if gain > max_gain:\n            max_gain = gain\n            max_feat = feature\n    root.value = max_feat\n    #print (\"\\nMax feature attr\",max_feat)\n    uniq = np.unique(examples[max_feat])\n    #print (\"\\n\",uniq)\n    for u in uniq:\n        #print (\"\\n\",u)\n        subdata = examples[examples[max_feat] == u]\n        #print (\"\\n\",subdata)\n        if entropy(subdata) == 0.0:\n            newNode = Node()\n            newNode.isLeaf = True\n            newNode.value = u\n            newNode.pred = np.unique(subdata[\"answer\"])\n            root.children.append(newNode)\n        else:\n            dummyNode = Node()\n            dummyNode.value = u\n            new_attrs = attrs.copy()\n            new_attrs.remove(max_feat)\n            child = ID3(subdata, new_attrs)\n            dummyNode.children.append(child)\n            root.children.append(dummyNode)\n\n    return root\n\ndef printTree(root: Node, depth=0):\n    for i in range(depth):\n        print(\"\\t\", end=\"\")\n    print(root.value, end=\"\")\n    if root.isLeaf:\n        print(\" -> \", root.pred)\n    print()\n    for child in root.children:\n        printTree(child, depth + 1)\n\ndef classify(root: Node, new):\n    for child in root.children:\n        if child.value == new[root.value]:\n            if child.isLeaf:\n                print (\"Predicted Label for new example\", new,\" is:\", child.pred)\n                exit\n            else:\n                classify (child.children[0], new)\n\nroot = ID3(data, features)\nprint(\"Decision Tree is:\")\nprintTree(root)\nprint (\"------------------\")\n\nnew = {\"outlook\":\"sunny\", \"temperature\":\"hot\", \"humidity\":\"normal\", \"wind\":\"strong\"}\nclassify (root, new)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T09:36:43.984264Z","iopub.execute_input":"2023-05-03T09:36:43.984737Z","iopub.status.idle":"2023-05-03T09:36:44.046020Z","shell.execute_reply.started":"2023-05-03T09:36:43.984700Z","shell.execute_reply":"2023-05-03T09:36:44.044865Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Decision Tree is:\noutlook\n\tovercast ->  ['yes']\n\n\train\n\t\twind\n\t\t\tstrong ->  ['no']\n\n\t\t\tweak ->  ['yes']\n\n\tsunny\n\t\thumidity\n\t\t\thigh ->  ['no']\n\n\t\t\tnormal ->  ['yes']\n\n------------------\nPredicted Label for new example {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'normal', 'wind': 'strong'}  is: ['yes']\n","output_type":"stream"}]}]}